{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f40db93",
   "metadata": {},
   "source": [
    "## Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ba7bee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "400f615c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir la taille des images\n",
    "IMG_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d2d510",
   "metadata": {},
   "source": [
    "## Chemin d'accès des répertoires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "51fe3612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les chemins des répertoires contenant les images\n",
    "directory1 = \"Datasets/fingers/train\"\n",
    "directory2 = \"Datasets/fingers/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d755772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les images du premier répertoire\n",
    "data1 = []\n",
    "for img in os.listdir(directory1):\n",
    "    try:\n",
    "        # Lire l'image en niveaux de gris\n",
    "        img_array = cv2.imread(os.path.join(directory1, img), cv2.IMREAD_GRAYSCALE)\n",
    "        # Redimensionner l'image\n",
    "        resized_img = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "        # Ajouter l'image redimensionnée à la liste des données avec le label approprié\n",
    "        data1.append([resized_img, 0])  # Supposez que 0 représente la catégorie du premier dossier\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "51a92ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les images du deuxième répertoire\n",
    "data2 = []\n",
    "for img in os.listdir(directory2):\n",
    "    try:\n",
    "        # Lire l'image en niveaux de gris\n",
    "        img_array = cv2.imread(os.path.join(directory2, img), cv2.IMREAD_GRAYSCALE)\n",
    "        # Redimensionner l'image\n",
    "        resized_img = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "        # Ajouter l'image redimensionnée à la liste des données avec le label approprié\n",
    "        data2.append([resized_img, 1])  # Supposez que 1 représente la catégorie du deuxième dossier\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "484072c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fusionner les données des deux répertoires\n",
    "data = data1 + data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2c173321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mélanger les données\n",
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "78e16b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparer les features (X) et les labels (y)\n",
    "X = []\n",
    "y = []\n",
    "for features, label in data:\n",
    "    X.append(features)\n",
    "    y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5a8372df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille des données X : (0, 128, 128, 1)\n",
      "Taille des labels y : (0,)\n"
     ]
    }
   ],
   "source": [
    "# Transformer X et y en tableaux NumPy\n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)  # -1 indique que la taille peut varier, 1 pour une seule chaîne de couleur (niveaux de gris)\n",
    "y = np.array(y)\n",
    "\n",
    "# Normaliser les valeurs des pixels pour qu'elles soient comprises entre 0 et 1\n",
    "X = X / 255.0\n",
    "\n",
    "# Afficher la taille des données et des labels\n",
    "print(\"Taille des données X :\", X.shape)\n",
    "print(\"Taille des labels y :\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e86810",
   "metadata": {},
   "source": [
    "## Définition du modèle CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dc9b73dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22e06c3",
   "metadata": {},
   "source": [
    "### Ajout des couches de convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "80b018cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e08a1f5",
   "metadata": {},
   "source": [
    "### Ajout des couches dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "db87a238",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(6, activation='softmax')) #6 classes de sorties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc391a85",
   "metadata": {},
   "source": [
    "### Compiler le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "991d6d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',  # Utilisez categorical_crossentropy\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb712bd",
   "metadata": {},
   "source": [
    "### Afficher le résumé du modèle crééer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d16c9674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_14 (Conv2D)          (None, 126, 126, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPooli  (None, 63, 63, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 61, 61, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPooli  (None, 30, 30, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 28, 28, 64)        36928     \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 50176)             0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                3211328   \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3267462 (12.46 MB)\n",
      "Trainable params: 3267462 (12.46 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e7293d",
   "metadata": {},
   "source": [
    "### Entrainer le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cdf261c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(X, \n\u001b[0;32m----> 2\u001b[0m                     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mto_categorical(y), \n\u001b[1;32m      3\u001b[0m                     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, \n\u001b[1;32m      4\u001b[0m                     validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/np_utils.py:71\u001b[0m, in \u001b[0;36mto_categorical\u001b[0;34m(y, num_classes, dtype)\u001b[0m\n\u001b[1;32m     69\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m num_classes:\n\u001b[0;32m---> 71\u001b[0m     num_classes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(y) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     72\u001b[0m n \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     73\u001b[0m categorical \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((n, num_classes), dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mamax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:2820\u001b[0m, in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2703\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_amax_dispatcher)\n\u001b[1;32m   2704\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mamax\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[1;32m   2705\u001b[0m          where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[1;32m   2706\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2707\u001b[0m \u001b[38;5;124;03m    Return the maximum of an array or maximum along an axis.\u001b[39;00m\n\u001b[1;32m   2708\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2818\u001b[0m \u001b[38;5;124;03m    5\u001b[39;00m\n\u001b[1;32m   2819\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2820\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapreduction(a, np\u001b[38;5;241m.\u001b[39mmaximum, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, axis, \u001b[38;5;28;01mNone\u001b[39;00m, out,\n\u001b[1;32m   2821\u001b[0m                           keepdims\u001b[38;5;241m=\u001b[39mkeepdims, initial\u001b[38;5;241m=\u001b[39minitial, where\u001b[38;5;241m=\u001b[39mwhere)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ufunc\u001b[38;5;241m.\u001b[39mreduce(obj, axis, dtype, out, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, \n",
    "                    tf.keras.utils.to_categorical(y), \n",
    "                    epochs=10, \n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef1c511",
   "metadata": {},
   "source": [
    "### Afficher le résultat de l'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad766e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
